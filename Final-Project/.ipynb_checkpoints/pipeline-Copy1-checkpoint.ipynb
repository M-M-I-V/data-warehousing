{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e75c3070-fae5-4815-bee4-19a85861ad20",
   "metadata": {},
   "source": [
    "## Import Required Libraries\n",
    "We import all the libraries needed for data cleaning and preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e44a6f4c-ea1e-4258-a5d9-00994b0fd63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The primary library for data manipulation and analysis, used for creating and working with DataFrames.\n",
    "import pandas as pd\n",
    "\n",
    "# The fundamental library for numerical computing in Python, often used for array operations and mathematical functions.\n",
    "import numpy as np\n",
    "\n",
    "# A scikit-learn class used for handling missing values (e.g., filling with mean, median, or constant).\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b00a4d-963e-4778-af82-6bf1dd55b180",
   "metadata": {},
   "source": [
    "## Cleaning Diagnoses Dataset\n",
    "Steps performed:\n",
    "1. Load dataset\n",
    "2. Remove duplicates\n",
    "3. Fill missing values for diagnosis code & description\n",
    "4. Remove invalid codes (e.g., \"XXX\")\n",
    "5. Standardize text formatting\n",
    "6. Enforce one-to-one code consistency per diagnosis\n",
    "7. Convert data types\n",
    "8. Export cleaned file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "192291e2-3947-43e3-974a-3f161130df13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diagnoses Cleaned Dataset:\n",
      "      diagnosis_id diagnosis_code   description\n",
      "0               1           D004      Covid-19\n",
      "1               2           D003  Hypertension\n",
      "2               3           D005           Flu\n",
      "3               4           D004      Covid-19\n",
      "4               5           D004      Covid-19\n",
      "..            ...            ...           ...\n",
      "115           116           D001        Asthma\n",
      "116           117           D001        Asthma\n",
      "117           118           D005           Flu\n",
      "118           119           D005           Flu\n",
      "119           120           D004      Covid-19\n",
      "\n",
      "[118 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"diagnoses.csv\")\n",
    "\n",
    "# Remove duplicate rows\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Impute missing diagnosis code and description (Flatten result!)\n",
    "df[\"diagnosis_code\"] = SimpleImputer(strategy=\"most_frequent\") \\\n",
    "    .fit_transform(df[[\"diagnosis_code\"]]).ravel()\n",
    "\n",
    "df[\"description\"] = SimpleImputer(strategy=\"most_frequent\") \\\n",
    "    .fit_transform(df[[\"description\"]]).ravel()\n",
    "\n",
    "# Remove invalid code entries\n",
    "df = df[df[\"diagnosis_code\"] != \"XXX\"]\n",
    "\n",
    "# Format description text\n",
    "df[\"description\"] = df[\"description\"].str.strip().str.title()\n",
    "df[\"description\"] = df[\"description\"].str.replace(\"Unk\", \"Unknown\")\n",
    "\n",
    "# Determine primary suggested code\n",
    "mode_mapping = df.groupby(\"description\")[\"diagnosis_code\"].agg(\n",
    "    lambda x: x.mode()[0] if not x.mode().empty else np.nan\n",
    ").to_dict()\n",
    "\n",
    "primary_descriptions = [desc for desc in mode_mapping if desc != 'Unknown']\n",
    "\n",
    "all_codes = set(df['diagnosis_code'].unique())\n",
    "used_codes = set()\n",
    "consistent_map_final = {}\n",
    "\n",
    "for desc in primary_descriptions:\n",
    "    suggested_code = mode_mapping[desc]\n",
    "\n",
    "    if suggested_code not in used_codes:\n",
    "        consistent_map_final[desc] = suggested_code\n",
    "        used_codes.add(suggested_code)\n",
    "    else:\n",
    "        available_codes = sorted(all_codes - used_codes, key=str)\n",
    "\n",
    "        if available_codes:\n",
    "            new_code = available_codes[0]\n",
    "        else:\n",
    "            new_code = \"C999\"\n",
    "            while new_code in used_codes:\n",
    "                new_code = f\"C{int(new_code[1:]) + 1}\"\n",
    "\n",
    "        consistent_map_final[desc] = new_code\n",
    "        used_codes.add(new_code)\n",
    "\n",
    "# Handle Unknown\n",
    "if 'Unknown' in mode_mapping:\n",
    "    consistent_map_final['Unknown'] = mode_mapping['Unknown']\n",
    "\n",
    "# Apply mapping\n",
    "df[\"diagnosis_code\"] = df[\"description\"].map(consistent_map_final)\n",
    "\n",
    "# Convert to proper data types\n",
    "df = df.astype({\n",
    "    \"diagnosis_id\": \"int\",\n",
    "    \"diagnosis_code\": \"str\",\n",
    "    \"description\": \"str\"\n",
    "})\n",
    "\n",
    "print(\"Diagnoses Cleaned Dataset:\\n\", df)\n",
    "\n",
    "# Save cleaned file\n",
    "df.to_csv(\"diagnoses_cleaned.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b402750c-fb26-4431-bb68-2874ec36e8f8",
   "metadata": {},
   "source": [
    "## Cleaning Patients Dataset\n",
    "Steps performed:\n",
    "1. Load dataset\n",
    "2. Fill missing names\n",
    "3. Fix age errors and impute missing values\n",
    "4. Normalize gender values\n",
    "5. Remove duplicate patient records\n",
    "6. Export cleaned file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd8def15-3897-4b4a-b660-b78415d5a67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patients Cleaned Dataset:\n",
      "      patient_id first_name last_name  gender  age\n",
      "0             1      Alice    Wilson  Female   52\n",
      "1             2    Charlie     Smith    Male   93\n",
      "2             3       Jane   Johnson  Female   15\n",
      "3             4      Ethan     Smith  Female   72\n",
      "4             5       Jane    Miller  Female   61\n",
      "..          ...        ...       ...     ...  ...\n",
      "115         116      Ethan     Smith  Female   81\n",
      "116         117      Alice     Smith  Female   49\n",
      "117         118      Diana     Brown    Male   35\n",
      "118         119      Fiona     Brown  Female   35\n",
      "119         120      Fiona    Wilson    Male   33\n",
      "\n",
      "[120 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"patients.csv\")\n",
    "\n",
    "# Fix missing & incorrectly formatted names\n",
    "df['first_name'] = df['first_name'].fillna(\"Unknown\")\n",
    "df['last_name'] = df['last_name'].str.rstrip(\"#\").str.title()\n",
    "\n",
    "# Remove invalid ages (negative or unrealistic)\n",
    "df.loc[(df['age'] < 0) | (df['age'] > 120), 'age'] = None\n",
    "\n",
    "# Impute missing age with mean\n",
    "df[['age']] = SimpleImputer(strategy='mean').fit_transform(df[['age']])\n",
    "df['age'] = df['age'].astype(int)\n",
    "\n",
    "# Normalize gender values\n",
    "df['gender'] = df['gender'].str.strip().str.upper().replace({\n",
    "    'M': 'Male',\n",
    "    'F': 'Female'\n",
    "})\n",
    "\n",
    "# Remove duplicate patients\n",
    "df = df.drop_duplicates(subset=['patient_id'])\n",
    "\n",
    "print(\"Patients Cleaned Dataset:\\n\", df)\n",
    "\n",
    "# Save cleaned file\n",
    "df.to_csv(\"patients_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4e92f2-6fa5-499e-bbc8-ae878aaa755f",
   "metadata": {},
   "source": [
    "## Cleaning Treatments Dataset\n",
    "Steps performed:\n",
    "1. Load dataset and remove duplicates\n",
    "2. Fix missing doctor names and costs\n",
    "3. Replace invalid entries\n",
    "4. Clean text formatting\n",
    "5. Convert dates properly\n",
    "6. Handle negative/extreme treatment costs\n",
    "7. Convert data types\n",
    "8. Export cleaned file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dec30450-11ec-4621-8a86-05a1912ac686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treatments Cleaned Dataset:\n",
      "      admission_id  patient_id doctor_name          department  diagnosis_id  \\\n",
      "0               1          50   Dr. Evans            Oncology             1   \n",
      "1               2          61   Dr. Evans           Neurology            78   \n",
      "2               3          51   Dr. Adams           Neurology           115   \n",
      "3               4          19   Dr. Adams  Unknown Department            47   \n",
      "4               5          21   Dr. Evans          Pediatrics           114   \n",
      "..            ...         ...         ...                 ...           ...   \n",
      "115           116          64   Dr. Adams          Cardiology            74   \n",
      "116           117          98   Dr. Evans             General            30   \n",
      "117           118          59   Dr. Evans             General           120   \n",
      "118           119          56   Dr. Clark          Pediatrics            59   \n",
      "119           120          59   Dr. Adams           Neurology           110   \n",
      "\n",
      "    admission_date  treatment_cost  \n",
      "0       2023-05-08         49854.0  \n",
      "1       2023-12-22         21607.0  \n",
      "2       2023-10-06         38599.0  \n",
      "3       2023-02-24         29529.0  \n",
      "4       2023-10-20         36954.0  \n",
      "..             ...             ...  \n",
      "115     2023-11-29         25791.0  \n",
      "116     2023-02-05          1338.0  \n",
      "117     2023-04-16         25063.0  \n",
      "118     2023-08-08        200000.0  \n",
      "119     2023-03-25         12344.0  \n",
      "\n",
      "[120 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"treatments.csv\")\n",
    "\n",
    "# Remove duplicates\n",
    "df = df.drop_duplicates().copy()\n",
    "\n",
    "# Fix missing doctor names & treatment costs\n",
    "df[\"doctor_name\"] = SimpleImputer(strategy=\"most_frequent\") \\\n",
    "    .fit_transform(df[[\"doctor_name\"]]).ravel()\n",
    "df[\"treatment_cost\"] = SimpleImputer(strategy=\"median\") \\\n",
    "    .fit_transform(df[[\"treatment_cost\"]]).ravel()\n",
    "\n",
    "# Replace invalid text entries\n",
    "df.loc[df[\"doctor_name\"].str.contains(\"\\?\\?\\?\", na=False), \"doctor_name\"] = \"Unknown Doctor\"\n",
    "df.loc[df[\"department\"] == \"UnknownDept\", \"department\"] = \"Unknown Department\"\n",
    "\n",
    "# Standardize text formatting\n",
    "df[\"doctor_name\"] = df[\"doctor_name\"].str.strip().str.title()\n",
    "df[\"department\"] = df[\"department\"].str.strip().str.title()\n",
    "\n",
    "# Convert date values\n",
    "df[\"admission_date\"] = pd.to_datetime(df[\"admission_date\"], errors=\"coerce\")\n",
    "\n",
    "# Fix negative & too-high treatment costs\n",
    "df.loc[df[\"treatment_cost\"] < 0, \"treatment_cost\"] = np.nan\n",
    "df[\"treatment_cost\"] = SimpleImputer(strategy=\"median\").fit_transform(df[[\"treatment_cost\"]])\n",
    "df.loc[df[\"treatment_cost\"] > 200000, \"treatment_cost\"] = 200000\n",
    "\n",
    "# Convert to proper data types\n",
    "df = df.astype({\n",
    "    \"admission_id\": \"int\",\n",
    "    \"patient_id\": \"int\",\n",
    "    \"diagnosis_id\": \"int\",\n",
    "    \"department\": \"str\",\n",
    "    \"doctor_name\": \"str\"\n",
    "})\n",
    "\n",
    "print(\"Treatments Cleaned Dataset:\\n\", df)\n",
    "\n",
    "# Save cleaned file\n",
    "df.to_csv(\"treatments_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac48f3f0-debe-4370-9632-b73ae6dcadd9",
   "metadata": {},
   "source": [
    "## SQL Script Execution for ETL\n",
    "\n",
    "This step runs the `script.sql` file which contains all SQL statements for:\n",
    "1. Creating OLTP tables  \n",
    "2.  Loading CSV datasets  \n",
    "3.  Creating Data Warehouse dimension & fact tables  \n",
    "4.  Transforming and inserting data into the DW\n",
    "\n",
    "Execution is done using a database transaction:\n",
    "- If all commands succeed → Commit to MySQL\n",
    "- If any command fails → Rollback all changes\n",
    "\n",
    "A log file named `etl_sql_execution.log` is generated to store execution details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8bb9ecb-a9a0-4224-9f85-c0cbcd9031da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL script executed successfully!\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "import logging\n",
    "import os\n",
    "\n",
    "# Logger Setup\n",
    "logging.basicConfig(\n",
    "    filename=\"etl_sql_execution.log\",\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "SQL_FILE = \"script.sql\"\n",
    "\n",
    "# Check if SQL script exists\n",
    "if not os.path.exists(SQL_FILE):\n",
    "    raise FileNotFoundError(f\"{SQL_FILE} not found!\")\n",
    "\n",
    "try:\n",
    "    # Connect to MySQL\n",
    "    connection = mysql.connector.connect(\n",
    "        host=\"localhost\",\n",
    "        user=\"root\",\n",
    "        password=\"\",\n",
    "        database=\"healthcare_dw\",\n",
    "        allow_local_infile=True\n",
    "    )\n",
    "\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    # Load SQL script\n",
    "    with open(SQL_FILE, \"r\") as file:\n",
    "        sql_script = file.read()\n",
    "\n",
    "    logging.info(\"SQL script loaded successfully.\")\n",
    "\n",
    "    # Execute SQL script transactionally\n",
    "    statements = sql_script.split(';')\n",
    "    executed_count = 0\n",
    "\n",
    "    for statement in statements:\n",
    "        stmt = statement.strip()\n",
    "        if stmt:\n",
    "            cursor.execute(stmt)\n",
    "            executed_count += 1\n",
    "            logging.info(f\"Executed statement: {stmt[:50]}...\")\n",
    "\n",
    "    connection.commit()\n",
    "    logging.info(f\"Script executed successfully. ({executed_count} statements)\")\n",
    "\n",
    "    print(\"SQL script executed successfully!\")\n",
    "\n",
    "except mysql.connector.Error as err:\n",
    "    connection.rollback()\n",
    "    logging.error(f\"Error occurred: {err}\")\n",
    "    print(f\"Execution failed. Rolled back changes: {err}\")\n",
    "\n",
    "finally:\n",
    "    if cursor:\n",
    "        cursor.close()\n",
    "    if connection:\n",
    "        connection.close()\n",
    "    logging.info(\"Database connection closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e86985c-3b9a-4432-9ddf-23b73006d323",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8062f0-7cf6-4058-9800-55f97bd92779",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
